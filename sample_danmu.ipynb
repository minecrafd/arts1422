{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import chardet\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from bixin import predict\n",
    "import snownlp\n",
    "import dm_pb2 as Danmaku\n",
    "import sklearn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0,\n",
      " 'data': [{'cid': 1105215233,\n",
      "           'dimension': {'height': 1920, 'rotate': 0, 'width': 3840},\n",
      "           'duration': 87,\n",
      "           'first_frame': 'http://i0.hdslb.com/bfs/storyff/n230422a219gylliozq0r520l6kdz8f1_firsti.jpg',\n",
      "           'from': 'vupload',\n",
      "           'page': 1,\n",
      "           'part': '【4K修复+60帧】小鬼 泰裤辣（原版）',\n",
      "           'vid': '',\n",
      "           'weblink': ''}],\n",
      " 'message': '0',\n",
      " 'ttl': 1}\n",
      "1105215233\n"
     ]
    }
   ],
   "source": [
    "# 1.根据bvid请求得到cid\n",
    "bvid = \"BV1bc411H7Gv\"\n",
    "def get_cid():\n",
    "    url = 'https://api.bilibili.com/x/player/pagelist?bvid=BV1bc411H7Gv'\n",
    "    res = requests.get(url).text\n",
    "    json_dict = json.loads(res)\n",
    "    pprint(json_dict)\n",
    "    return (json_dict[\"data\"][0][\"duration\"], json_dict[\"data\"][0][\"cid\"])\n",
    "(max_time, cid) = get_cid()\n",
    "max_time = max_time * 1000\n",
    "\n",
    "print(cid)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# 更新：新版api需要使用proto获取弹幕文件\n",
    "def get_prot_dm(cid):\n",
    "    url = 'https://api.bilibili.com/x/v2/dm/web/seg.so'\n",
    "    params = {\n",
    "        'type': 1,         # 弹幕类型\n",
    "        'oid': cid,    # cid\n",
    "        'segment_index': 1 # 弹幕分段\n",
    "    }\n",
    "    resp = requests.get(url, params)\n",
    "    data = resp.content\n",
    "\n",
    "    danmaku_seg = Danmaku.DmSegMobileReply()\n",
    "    danmaku_seg.ParseFromString(data)\n",
    "\n",
    "    return danmaku_seg.elems\n",
    "\n",
    "danmu_proto = get_prot_dm(cid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       id  progress    content\n",
      "0     1301402202560179456     23493         哥哥\n",
      "1     1301445531851347456       324       我40帧\n",
      "4     1301467215505580032     52312       油光满面\n",
      "5     1301468690323432448     76163       音乐骤停\n",
      "8     1301487277205294592     51629       脚趾扣地\n",
      "...                   ...       ...        ...\n",
      "3382  1310799634725521408     64658       要来力喜\n",
      "3383  1310810228899852544      1924       我擦深圳\n",
      "3384  1310812124808779264       659      我死在深圳\n",
      "3386  1310828580598763776     30641        yue\n",
      "3387  1310839748100811008      7618  什么都修复哈哈哈哈\n",
      "\n",
      "[2609 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#得到弹幕 array\n",
    "def to_list(prot):\n",
    "    l = []\n",
    "    for i in range(len(prot)):\n",
    "        l.append({})\n",
    "        l[i][\"id\"] = prot[i].id\n",
    "        l[i][\"progress\"] = prot[i].progress\n",
    "        l[i][\"content\"] = prot[i].content\n",
    "\n",
    "    return l\n",
    "listed_danmu = to_list(danmu_proto)\n",
    "df = pd.DataFrame(listed_danmu)\n",
    "mask = df['content'].str.len() > 10\n",
    "df = df[~mask]\n",
    "df['content'] = df['content'].str.replace('[^\\w\\s]', '')\n",
    "mask = df['content'].str.len() < 1\n",
    "df = df[~mask]\n",
    "df.dropna(subset=['content'], inplace=True)\n",
    "mask = df['content'].str.len() == 0\n",
    "df = df[~mask]\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       content  count\n",
      "0         我测深圳     29\n",
      "1       给我点鸡叫声     13\n",
      "2   什么都修复只会害了你     11\n",
      "3    什么都修只会害了你      9\n",
      "4         我是丁真      9\n",
      "5        我死在深圳      9\n",
      "6         我40帧      7\n",
      "7          泰裤辣      6\n",
      "8       给我点滋尿声      5\n",
      "9         我是深圳      4\n",
      "10         抬裤拉      4\n",
      "11        油光满面      4\n",
      "     content  count\n",
      "0        董明珠     12\n",
      "1         病句     10\n",
      "2       油光满面      9\n",
      "3   如约而至地出现了      9\n",
      "4        泰裤辣      9\n",
      "5          油      6\n",
      "6        泰裤啦      6\n",
      "7        泰油辣      4\n",
      "8       杰夫哈迪      4\n",
      "9         好油      4\n",
      "10    我还是在这里      4\n",
      "  content  count\n",
      "0     住医院     15\n",
      "1    家电下乡     11\n",
      "2     泰裤辣      7\n",
      "3     yue      4\n",
      "4     做阴乐      4\n",
      "    content  count\n",
      "0     那可太好了     25\n",
      "1       泰裤辣     10\n",
      "2   哈哈哈哈哈哈哈      9\n",
      "3    真的吗我不信      8\n",
      "4       真的吗      8\n",
      "5      油光满面      6\n",
      "6         油      6\n",
      "7       我不信      6\n",
      "8     那可泰好了      6\n",
      "9        假的      5\n",
      "10      好尴尬      5\n",
      "11      尬死了      4\n",
      "  content  count\n",
      "0     要来力     56\n",
      "1    开始吟唱     15\n",
      "2    要来力喜      9\n",
      "3     泰裤辣      7\n",
      "4    全文背诵      5\n",
      "5     我不管      4\n",
      "  content  count\n",
      "0     泰裤辣    174\n",
      "1     要来力     43\n",
      "2     泰裤啦     16\n",
      "3     泰酷辣     16\n",
      "4     太酷啦      6\n",
      "5    全体起立      4\n"
     ]
    }
   ],
   "source": [
    "#divide into 6 parts according to time variation\n",
    "def classify_sentiment(s):\n",
    "    if(s<0.166):\n",
    "        return 0\n",
    "    if(s<0.333):\n",
    "        return 1\n",
    "    if(s<0.5):\n",
    "        return 2\n",
    "    if(s<0.666):\n",
    "        return 3\n",
    "    if(s<0.833):\n",
    "        return 4\n",
    "    if(s<=1):\n",
    "        return 5\n",
    "def get_sentiment(text):\n",
    "    s = snownlp.SnowNLP(text)\n",
    "    return classify_sentiment(s.sentiments)\n",
    "index = 0\n",
    "for i in range(6):\n",
    "    start_time = max_time * i / 6\n",
    "    end_time = max_time * (i+1) / 6\n",
    "    tmp = df[(df['progress'] >= start_time) & (df['progress'] <= end_time)]\n",
    "    tmp = tmp['content'].value_counts()\n",
    "    tmp = pd.DataFrame({'content': tmp.index, 'count': tmp.values})\n",
    "    mask = tmp['count'].values <= 3\n",
    "    tmp = tmp[~mask]\n",
    "    print(tmp)\n",
    "    tmp['emo'] = tmp['content'].apply(get_sentiment)\n",
    "    tmp.to_csv(\"video_\"+str(index)+\".csv\")\n",
    "    index+=1\n",
    "\n",
    "df.to_csv(\"video.csv\")\n",
    "counts = df['content'].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# 2.根据cid请求弹幕，解析弹幕得到最终的数据\n",
    "\n",
    "# def get_data(cid):\n",
    "#     final_url = \"https://api.bilibili.com/x/v1/dm/list.so?oid=\" + str(cid)\n",
    "#     final_res = requests.get(final_url)\n",
    "#     final_res.encoding = chardet.detect(final_res.content)['encoding']\n",
    "#     final_res = final_res.text\n",
    "#     pattern = re.compile('<d.*?>(.*?)</d>')\n",
    "#     match = re.compile(r'<d\\s+[^>]*\\bp=\"([^\"]*)\"')\n",
    "#     pa = match.findall(final_res)\n",
    "#\n",
    "#     data = pattern.findall(final_res)\n",
    "#     danmu_time = [float(item.split(',')[0]) for item in pa]\n",
    "#     danmu_mode = [float(item.split(',')[1]) for item in pa]\n",
    "#     danmu_size = [float(item.split(',')[2]) for item in pa]\n",
    "#     danmu_color = [float(item.split(',')[3]) for item in pa]\n",
    "#     danmu_abstime = [float(item.split(',')[4]) for item in pa]\n",
    "#     danmu_pool = [float(item.split(',')[5]) for item in pa]\n",
    "#     danmu_id = [(item.split(',')[6]) for item in pa]\n",
    "#     danmu_rowid = [float(item.split(',')[7]) for item in pa]\n",
    "#     print(len(data))\n",
    "#     return (data, danmu_time, danmu_mode, danmu_size, danmu_color, danmu_abstime, danmu_pool, danmu_id, danmu_rowid)\n",
    "#\n",
    "#\n",
    "# (danmu_text, danmu_time, danmu_mode, danmu_size, danmu_color, danmu_abstime, danmu_pool, danmu_id, danmu_rowid) = get_data(cid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# # 分割弹幕为八个部分\n",
    "# # 视频持续时间\n",
    "# max_time = max(danmu_time)\n",
    "# divided_danmu = []\n",
    "# for i in range(8):\n",
    "#     time_start = max_time * (i/8)\n",
    "#     time_stop = max_time * ((i+1)/8)\n",
    "#     for j in range(len(danmu_time)):\n",
    "#         if time_start <= danmu_time[j] <= time_stop:\n",
    "#             divided_danmu.append([i, danmu_text[j]])\n",
    "# print(len(danmu_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# export csv\n",
    "# arr = np.array(divided_danmu)\n",
    "# df = pd.DataFrame(arr)\n",
    "# df.to_csv(\"video.csv\", header=[\"label\", \"text\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aid': 442960465, 'videos': 1, 'tid': 126, 'tname': '人力VOCALOID', 'copyright': 1, 'pic': 'http://i0.hdslb.com/bfs/archive/4508d4fec623d274cc1f475613a980e96eea5e40.jpg', 'title': '⚡泰 裤 辣—最阴间版本⚡', 'pubdate': 1682330406, 'ctime': 1682330406, 'desc': '如果，你们看了视频，能给up主两个小小的，圆圆的东西，那可真的.....\\n制作：天气温云', 'state': 0, 'duration': 92, 'mission_id': 1377412, 'rights': {'bp': 0, 'elec': 0, 'download': 0, 'movie': 0, 'pay': 0, 'hd5': 1, 'no_reprint': 1, 'autoplay': 1, 'ugc_pay': 0, 'is_cooperation': 0, 'ugc_pay_preview': 0, 'no_background': 0, 'arc_pay': 0, 'pay_free_watch': 0}, 'owner': {'mid': 110371677, 'name': '天气温云', 'face': 'https://i0.hdslb.com/bfs/face/1638b504df4bcb91a8626f1c96981e03ff086737.jpg'}, 'stat': {'aid': 442960465, 'view': 805827, 'danmaku': 753, 'reply': 485, 'favorite': 6764, 'coin': 3437, 'share': 5599, 'now_rank': 0, 'his_rank': 0, 'like': 27629, 'dislike': 0, 'vt': 0, 'vv': 805827}, 'dynamic': '', 'cid': 1107570473, 'dimension': {'width': 1920, 'height': 1080, 'rotate': 0}, 'season_id': 73676, 'short_link_v2': 'https://b23.tv/BV1RL411Y7Rq', 'first_frame': 'http://i2.hdslb.com/bfs/storyff/n230424a22krhuzo6g5sap1hi6onumzn_firsti.jpg', 'pub_location': '四川', 'bvid': 'BV1RL411Y7Rq', 'season_type': 1, 'is_ogv': False, 'ogv_info': None, 'rcmd_reason': ''}\n"
     ]
    }
   ],
   "source": [
    "def get_relate(bvid):\n",
    "    # 设置请求参数\n",
    "    params = {\n",
    "        \"bvid\": bvid,  # 你想获取推荐视频的原始视频的bid\n",
    "        \"num\": 1,  # 获取的推荐视频数量，最多为40\n",
    "    }\n",
    "\n",
    "    # 发送请求\n",
    "    response = requests.get(\"https://api.bilibili.com/x/web-interface/archive/related\", params=params)\n",
    "\n",
    "    # 解析响应\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        recommend_list = data.get(\"data\")\n",
    "        # 处理推荐视频列表数据\n",
    "        return recommend_list\n",
    "    else:\n",
    "        print(\"请求失败\")\n",
    "\n",
    "relate_list = get_relate(bvid)\n",
    "print(relate_list[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "               id  progress   content\n0    1.298707e+10     40683        离谱\n2    1.298803e+10     50727       要来力\n3    1.298814e+10     25275  让世界爱上中国造\n4    1.298818e+10     27081        笑了\n6    1.299011e+10     30611     感动泪目了\n..            ...       ...       ...\n681  1.310419e+10     36184       够阴间\n682  1.310450e+10     12117       腾敬萧\n683  1.310450e+10      3836       你个头\n685  1.310462e+10     37111  你就是个嘬嘬嘬嘬\n688  1.310825e+10     48553    我真的蚌埠住\n\n[28591 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>progress</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.298707e+10</td>\n      <td>40683</td>\n      <td>离谱</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.298803e+10</td>\n      <td>50727</td>\n      <td>要来力</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.298814e+10</td>\n      <td>25275</td>\n      <td>让世界爱上中国造</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.298818e+10</td>\n      <td>27081</td>\n      <td>笑了</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.299011e+10</td>\n      <td>30611</td>\n      <td>感动泪目了</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>1.310419e+10</td>\n      <td>36184</td>\n      <td>够阴间</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>1.310450e+10</td>\n      <td>12117</td>\n      <td>腾敬萧</td>\n    </tr>\n    <tr>\n      <th>683</th>\n      <td>1.310450e+10</td>\n      <td>3836</td>\n      <td>你个头</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>1.310462e+10</td>\n      <td>37111</td>\n      <td>你就是个嘬嘬嘬嘬</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>1.310825e+10</td>\n      <td>48553</td>\n      <td>我真的蚌埠住</td>\n    </tr>\n  </tbody>\n</table>\n<p>28591 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#迭代获取其他视频的推荐\n",
    "index = 0\n",
    "whole_related_df = pd.DataFrame()\n",
    "for it in relate_list:\n",
    "    danmu_relate = get_prot_dm(it['cid'])\n",
    "    #preprocess\n",
    "    listed_danmu = to_list(danmu_relate)\n",
    "    df = pd.DataFrame(listed_danmu)\n",
    "    mask = df['content'].str.len() > 10\n",
    "    df = df[~mask]\n",
    "    df['content'] = df['content'].str.replace('[^\\w\\s]', '')\n",
    "    df['content'] = df['content'].str.replace('哈', '')\n",
    "    df['content'] = df['content'].str.replace('嘿', '')\n",
    "    df['content'] = df['content'].str.replace('啊', '')\n",
    "    mask = df['content'].str.len() <= 1\n",
    "    df = df[~mask]\n",
    "    df.dropna(subset=['content'], inplace=True)\n",
    "    #end of preprocess\n",
    "    relate_tmp = df['content'].value_counts()\n",
    "    relate_tmp = pd.DataFrame({'content': relate_tmp.index, 'count': relate_tmp.values})\n",
    "    relate_tmp['emo'] = relate_tmp['content'].apply(get_sentiment)\n",
    "    relate_tmp.to_csv(\"relate_video_\"+str(index)+\".csv\")\n",
    "    whole_related_df = pd.concat([df, whole_related_df], axis=0)\n",
    "\n",
    "    index+=1\n",
    "\n",
    "whole_related_df['id'] /= 100000000\n",
    "whole_related_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# whole_count = whole_related_df['content'].value_counts()\n",
    "# whole_count = pd.DataFrame({'content': whole_count.index, 'count': whole_count.values})\n",
    "whole_count = whole_related_df.groupby('content').agg({'id': 'sum', 'content': 'size'}).rename(columns={'content': 'count'}).reset_index()\n",
    "mask = whole_count['count'].values <= 3\n",
    "whole_count = whole_count[~mask]\n",
    "whole_count\n",
    "whole_count['emo'] = whole_count['content'].apply(get_sentiment)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          content            id  count  emo\n",
      "120    3 4 做个好好先生  5.196653e+10      4    1\n",
      "147        4K频道精选  5.958601e+10      5    5\n",
      "149        4k频道精选  4.663501e+10      4    5\n",
      "162            66  1.044417e+11      8    0\n",
      "163           666  4.698578e+11     36    3\n",
      "...           ...           ...    ...  ...\n",
      "16824        鸡裤同笼  1.175777e+11      9    2\n",
      "16840          鸣人  6.541639e+10      5    5\n",
      "16907       黑红也是红  6.511902e+10      5    3\n",
      "16925        타이쿠라  6.514681e+10      5    3\n",
      "16929         테콜라  5.210563e+10      4    3\n",
      "\n",
      "[642 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": "          content            id  count  emo\n120    3 4 做个好好先生  5.196653e+10      4    1\n147        4K频道精选  5.958601e+10      5    5\n149        4k频道精选  4.663501e+10      4    5\n162            66  1.044417e+11      8    0\n163           666  4.698578e+11     36    3\n...           ...           ...    ...  ...\n16824        鸡裤同笼  1.175777e+11      9    2\n16840          鸣人  6.541639e+10      5    5\n16907       黑红也是红  6.511902e+10      5    3\n16925        타이쿠라  6.514681e+10      5    3\n16929         테콜라  5.210563e+10      4    3\n\n[642 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>id</th>\n      <th>count</th>\n      <th>emo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>120</th>\n      <td>3 4 做个好好先生</td>\n      <td>5.196653e+10</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>4K频道精选</td>\n      <td>5.958601e+10</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>4k频道精选</td>\n      <td>4.663501e+10</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>66</td>\n      <td>1.044417e+11</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>666</td>\n      <td>4.698578e+11</td>\n      <td>36</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16824</th>\n      <td>鸡裤同笼</td>\n      <td>1.175777e+11</td>\n      <td>9</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>16840</th>\n      <td>鸣人</td>\n      <td>6.541639e+10</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>16907</th>\n      <td>黑红也是红</td>\n      <td>6.511902e+10</td>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16925</th>\n      <td>타이쿠라</td>\n      <td>6.514681e+10</td>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16929</th>\n      <td>테콜라</td>\n      <td>5.210563e+10</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>642 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_count.to_csv(\"main.csv\")\n",
    "print(whole_count)\n",
    "whole_count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# 降维 用于主图\n",
    "# 使用t-SNE进行降维\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embedding = tsne.fit_transform(whole_count.drop('content', axis=1))\n",
    "\n",
    "# 创建降维后的DataFrame\n",
    "df_tsne = pd.DataFrame(embedding, columns=['Dimension 1', 'Dimension 2'])\n",
    "df_tsne['content'] = df['content']\n",
    "df_tsne.to_csv(\"tsne.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # 3.保存弹幕列表\n",
    "#\n",
    "# def save_to_file(data):\n",
    "#     with open(\"dan_mu.txt\", mode=\"w\", encoding=\"utf-8\") as f:\n",
    "#         for i in data:\n",
    "#             f.write(i)\n",
    "#             f.write(\"\\n\")\n",
    "# save_to_file(data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1 导入相关库\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 目标视频文件的处理\n",
    "df = pd.read_csv(\"video.csv\")\n",
    "array = np.array(df)\n",
    "content = array[:, 3]\n",
    "progress = array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 2 读取文本文件，并使用lcut()方法进行分词\n",
    "with open(\"video.csv\",encoding=\"utf-8\") as f:\n",
    "    txt = f.read()\n",
    "txt = txt.split()\n",
    "data_cut = [jieba.lcut(x) for x in txt]\n",
    "data_cut\n",
    "# 3 读取停用词\n",
    "stop = [\" \",\"道\",\"说道\",\"说\",'了']\n",
    "# 4 去掉停用词之后的最终词\n",
    "s_data_cut = pd.Series(data_cut)\n",
    "all_words_after = s_data_cut.apply(lambda x:[i for i in x if i not in stop])\n",
    "# 5 词频统计\n",
    "all_words = []\n",
    "for i in all_words_after:\n",
    "    all_words.extend(i)\n",
    "word_count = pd.Series(all_words).value_counts()\n",
    "# 6 词云图的绘制\n",
    "# 1）读取背景图片\n",
    "\n",
    "\n",
    "# 2）设置词云参数\n",
    "wc = WordCloud(font_path=\"C:/Users/Windows/fonts/simhei.ttf\",\n",
    "               background_color=\"white\",\n",
    "               max_words=2000,\n",
    "               max_font_size=200,\n",
    "               random_state=42\n",
    "              )\n",
    "wc2 = wc.fit_words(word_count)\n",
    "\n",
    "# 3）绘制词云图\n",
    "plt.figure(figsize=(16,8), dpi=300)\n",
    "plt.imshow(wc2)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "wc.to_file(\"ciyun.jpg\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
